{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Math\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeA = 1\n",
    "sizeB = 4700\n",
    "\n",
    "cat_nums = 10\n",
    "\n",
    "TaporMove = \"Tapping\"\n",
    "from skimage.transform import resize\n",
    "train_image = np.zeros((1, sizeA, sizeB))\n",
    "train_label = [0]\n",
    "train_audio_path = TaporMove + '/Training/'\n",
    "subfile = os.listdir(train_audio_path)\n",
    "subfile.sort()\n",
    "for i in range(cat_nums):\n",
    "\n",
    "    size = 10\n",
    "    out_image = np.zeros((size, sizeA, sizeB))\n",
    "    out_label = np.full((size), i)\n",
    "    for index in range(0, 10):\n",
    "        sample_rate, samples = wavfile.read(str(train_audio_path) + subfile[index+10*i])\n",
    "\n",
    "        new_sample_rate = 20000\n",
    "        resampled = signal.resample(samples, int(new_sample_rate/sample_rate * samples.shape[0]))\n",
    "        resampled = resampled[:sizeB]\n",
    "        s = resampled/np.sqrt(np.sum(np.square((np.abs(resampled))))/len(resampled))\n",
    "        \n",
    "        s_out = s.reshape((1, sizeA, sizeB))\n",
    "        out_image[index] = s_out\n",
    "    train_image = np.concatenate((train_image, out_image))\n",
    "    train_label = np.concatenate((train_label, out_label))\n",
    "x_train = train_image[1:]\n",
    "y_train = train_label[1:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_nums = 10\n",
    "\n",
    "TaporMove = \"Tapping\"\n",
    "from skimage.transform import resize\n",
    "test_image = np.zeros((1, sizeA, sizeB))\n",
    "test_label = [0]\n",
    "test_audio_path = TaporMove + '/Testing/'\n",
    "subfile = os.listdir(test_audio_path)\n",
    "subfile.sort()\n",
    "for i in range(cat_nums):\n",
    "\n",
    "    size = 10\n",
    "    out_image = np.zeros((size, sizeA, sizeB))\n",
    "    out_label = np.full((size), i)\n",
    "    for index in range(0, 10):\n",
    "        sample_rate, samples = wavfile.read(str(test_audio_path) + subfile[index+10*i])\n",
    "        new_sample_rate = 20000\n",
    "        resampled = signal.resample(samples, int(new_sample_rate/sample_rate * samples.shape[0]))\n",
    "        resampled = resampled[:sizeB]\n",
    "        s = resampled/np.sqrt(np.sum(np.square((np.abs(resampled))))/len(resampled))\n",
    "       \n",
    "        s_out = s.reshape((1, sizeA, sizeB))\n",
    "        out_image[index] = s_out\n",
    "    test_image = np.concatenate((test_image, out_image))\n",
    "    test_label = np.concatenate((test_label, out_label))\n",
    "x_test = test_image[1:]\n",
    "y_test = test_label[1:]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "train_shuffle_indices = np.random.permutation(np.arange(len(y_train)))\n",
    "test_shuffle_indices = np.random.permutation(np.arange(len(y_test)))\n",
    "\n",
    "x_test = x_test[test_shuffle_indices]\n",
    "x_train = x_train[train_shuffle_indices]\n",
    "y_test = y_test[test_shuffle_indices]\n",
    "y_train = y_train[train_shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29652311518>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(7, 4))\n",
    "samples = x_train[1].reshape((sizeB))\n",
    "plt.plot(np.linspace(0, new_sample_rate/len(samples), len(samples)), samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "tf.reset_default_graph()\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ke_size = 101\n",
    "X = tf.placeholder(shape=[None, sizeB, 1], dtype=tf.float32, name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_dim = int(((sizeB - ke_size+1)/step - ke_size+1)/step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-c559c0fd3365>:29: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From <ipython-input-12-c559c0fd3365>:69: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "caps1_n_maps = 32\n",
    "caps1_n_caps = caps1_n_maps * cap_dim# 2686主胶囊们  ##\n",
    "caps1_n_dims = 8\n",
    "\n",
    "conv1_params = {\n",
    "    \"filters\": caps1_n_maps * caps1_n_dims, # 256个卷积滤波器\n",
    "    \"kernel_size\": ke_size,\n",
    "    \"strides\": step,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu,\n",
    "}\n",
    "\n",
    "conv2_params = {\n",
    "    \"filters\": caps1_n_maps * caps1_n_dims, # 256个卷积滤波器\n",
    "    \"kernel_size\": ke_size,\n",
    "    \"strides\": step,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu\n",
    "}\n",
    "conv1 = tf.layers.conv1d(X, name=\"conv1\", **conv1_params)\n",
    "conv2 = tf.layers.conv1d(conv1, name=\"conv2\", **conv2_params)\n",
    "caps1_raw = tf.reshape(conv2, [-1, caps1_n_caps, caps1_n_dims],\n",
    "                       name=\"caps1_raw\")\n",
    "\n",
    "\n",
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(\"Squash\") as scope:    \n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=True, name=\"squared_norm\")\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon, name=\"safe_norm\")\n",
    "        squash_factor = tf.div(squared_norm , (1. + squared_norm), name=\"squash_factor\")\n",
    "        unit_vector = tf.div(s, safe_norm, name=\"unit_vector\")\n",
    "        return tf.multiply(squash_factor, unit_vector, name=name)\n",
    "\n",
    "    \n",
    "caps1_output = squash(caps1_raw, name=\"caps1_output\")\n",
    "\n",
    "caps2_n_caps = cat_nums\n",
    "caps2_n_dims = 16\n",
    "\n",
    "init_sigma = 0.1\n",
    "\n",
    "with tf.name_scope(\"expand_w_dimensions\") as scope:   \n",
    "    W_init = tf.random_normal(\n",
    "    shape=(1, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\n",
    "           stddev=init_sigma, dtype=tf.float32, name=\"W_init\")\n",
    "    W = tf.Variable(W_init, name=\"W\")\n",
    "    batch_size = tf.shape(X)[0]\n",
    "    W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\")\n",
    "\n",
    "with tf.name_scope(\"expand_caps1_output_dimensions\") as scope:   \n",
    "    caps1_output_expanded = tf.expand_dims(caps1_output, -1,\n",
    "                                           name=\"caps1_output_expanded\")\n",
    "    caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2,\n",
    "                                       name=\"caps1_output_tile\")\n",
    "    caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n_caps, 1, 1],\n",
    "                                 name=\"caps1_output_tiled\")\n",
    "\n",
    "    \n",
    "caps2_predicted = tf.matmul(W_tiled, caps1_output_tiled,\n",
    "                            name=\"caps2_predicted\")\n",
    "\n",
    "\n",
    "  \n",
    "def routing(w, name=None):\n",
    "    with tf.name_scope(\"routing\") as scope:   \n",
    "        routing_weights = tf.nn.softmax(w, \n",
    "                                        dim=2,\n",
    "                                        name=\"routing_weights\")\n",
    "        weighted_predictions = tf.multiply(routing_weights, \n",
    "                                           caps2_predicted,\n",
    "                                           name=\"weighted_predictions\")\n",
    "        weighted_sum = tf.reduce_sum(weighted_predictions, \n",
    "                                     axis=1, keep_dims=True,\n",
    "                                     name=\"weighted_sum\")\n",
    "        return squash(weighted_sum, axis=-2, name=name)\n",
    "\n",
    "\n",
    "\n",
    "def condition(input, counter):\n",
    "    return tf.less(counter, 3)\n",
    "\n",
    "def loop_body(input, counter):\n",
    "    caps2_output = routing(input, name=\"caps2_output\")\n",
    "    with tf.name_scope(\"update_weights\") as scope:\n",
    "        caps2_output_tiled = tf.tile(caps2_output, [1, caps1_n_caps, 1, 1, 1],\n",
    "                                     name=\"caps2_output_tiled\")\n",
    "        agreement = tf.matmul(caps2_predicted, caps2_output_tiled,\n",
    "                             transpose_a=True, name=\"agreement\")\n",
    "        output = tf.add(input, agreement, name=\"raw_weights_updated\")\n",
    "    return output, tf.add(counter, 1.0)\n",
    "        \n",
    "with tf.name_scope(\"routing_layer\"):\n",
    "    counter = tf.constant(1.0, dtype=np.float32)\n",
    "    raw_weights = tf.zeros([batch_size, caps1_n_caps, caps2_n_caps, 1, 1],\n",
    "                           dtype=np.float32, name=\"raw_weights\")\n",
    "    raw_weights_final,counters = tf.while_loop(condition, loop_body, [raw_weights, counter])\n",
    "\n",
    "caps2_output = routing(raw_weights_final, name=\"caps2_output\")\n",
    "\n",
    "\n",
    "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=keep_dims)\n",
    "        return tf.sqrt(squared_norm + epsilon)\n",
    "    \n",
    "with tf.name_scope(\"get_y_pred\") as scope:   \n",
    "    y_proba = safe_norm(caps2_output, axis=-2, name=\"y_proba\")\n",
    "    y_proba_argmax = tf.argmax(y_proba, axis=2, name=\"y_proba\")\n",
    "    y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")\n",
    "\n",
    "y = tf.placeholder(shape=[None], dtype=tf.int64, name=\"y\")\n",
    "\n",
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lambda_ = 0.5\n",
    "\n",
    "with tf.name_scope(\"calculate_margin_loss\") as scope:  \n",
    "    T = tf.one_hot(y, depth=caps2_n_caps, name=\"T\")\n",
    "    caps2_output_norm = safe_norm(caps2_output, axis=-2, keep_dims=True,\n",
    "                                  name=\"caps2_output_norm\")\n",
    "    present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm),\n",
    "                                  name=\"present_error_raw\")\n",
    "    present_error = tf.reshape(present_error_raw, shape=(-1, caps2_n_caps),\n",
    "                               name=\"present_error\")\n",
    "    absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus),\n",
    "                                 name=\"absent_error_raw\")\n",
    "    absent_error = tf.reshape(absent_error_raw, shape=(-1, caps2_n_caps),\n",
    "                              name=\"absent_error\")\n",
    "    L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error,\n",
    "               name=\"L\")\n",
    "    margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"margin_loss\")\n",
    "\n",
    "with tf.name_scope(\"mask_caps2_output\") as scope:  \n",
    "    mask_with_labels = tf.placeholder_with_default(False, shape=(),\n",
    "                                                   name=\"mask_with_labels\")\n",
    "    reconstruction_targets = tf.cond(mask_with_labels, # 条件\n",
    "                                     lambda: y,        # if True\n",
    "                                     lambda: y_pred,   # if False\n",
    "                                     name=\"reconstruction_targets\")\n",
    "    reconstruction_mask = tf.one_hot(reconstruction_targets,\n",
    "                                     depth=caps2_n_caps,\n",
    "                                     name=\"reconstruction_mask\")\n",
    "    reconstruction_mask_reshaped = tf.reshape(reconstruction_mask, [-1, 1, caps2_n_caps, 1, 1],\n",
    "                                              name=\"reconstruction_mask_reshaped\")\n",
    "    caps2_output_masked = tf.multiply(caps2_output, \n",
    "                                      reconstruction_mask_reshaped,\n",
    "                                      name=\"caps2_output_masked\")\n",
    "\n",
    "decoder_input = tf.reshape(caps2_output_masked,\n",
    "                           [-1, caps2_n_caps * caps2_n_dims],\n",
    "                           name=\"decoder_input\")\n",
    "\n",
    "n_hidden1 = 512\n",
    "n_hidden2 = 1024\n",
    "n_output = sizeA * sizeB ##\n",
    "\n",
    "with tf.name_scope(\"decoder\"):\n",
    "    hidden1 = tf.layers.dense(decoder_input, n_hidden1,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2,\n",
    "                              activation=tf.nn.relu,\n",
    "                              name=\"hidden2\")\n",
    "    decoder_output = tf.layers.dense(hidden2, n_output,\n",
    "                                     activation=tf.nn.sigmoid,\n",
    "                                     name=\"decoder_output\")\n",
    "\n",
    "with tf.name_scope(\"total_loss\"):\n",
    "    with tf.name_scope(\"get_reconstruction_loss\"):\n",
    "        X_flat = tf.reshape(X, [-1, n_output], name=\"X_flat\")\n",
    "        squared_difference = tf.square(X_flat - decoder_output,\n",
    "                                       name=\"squared_difference\")\n",
    "        reconstruction_loss = tf.reduce_mean(squared_difference,\n",
    "                                             name=\"reconstruction_loss\")\n",
    "    alpha = 0.0005\n",
    "    loss = tf.add(margin_loss, alpha * reconstruction_loss, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct = tf.equal(y, y_pred, name=\"correct\")\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "margin_loss_summary = tf.summary.scalar('Margin_loss', margin_loss)\n",
    "reconstruction_loss_summary = tf.summary.scalar('Reconstruction_loss', reconstruction_loss)\n",
    "loss_summary = tf.summary.scalar('Loss', loss)\n",
    "accur_summary = tf.summary.scalar('Accuracy', accuracy)\n",
    "Caps2_output_summary = tf.summary.histogram('Caps2_output', caps2_output)\n",
    "raw_weights_summary = tf.summary.histogram('raw_weights', raw_weights)\n",
    "merged_summary = tf.summary.merge_all()\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Val accuracy: 66.0000%  Loss: 0.323886 (improved)\n",
      "Epoch: 2  Val accuracy: 77.0000%  Loss: 0.226786 (improved)\n",
      "Epoch: 3  Val accuracy: 77.0000%  Loss: 0.183443 (improved)\n",
      "Epoch: 4  Val accuracy: 79.0000%  Loss: 0.162916 (improved)\n",
      "Epoch: 5  Val accuracy: 85.0000%  Loss: 0.156683 (improved)\n",
      "Epoch: 6  Val accuracy: 83.0000%  Loss: 0.149886 (improved)\n",
      "Epoch: 7  Val accuracy: 85.0000%  Loss: 0.149957\n",
      "Epoch: 8  Val accuracy: 85.0000%  Loss: 0.147296 (improved)\n",
      "Epoch: 9  Val accuracy: 88.0000%  Loss: 0.147753\n",
      "Epoch: 10  Val accuracy: 87.0000%  Loss: 0.148724\n",
      "Epoch: 11  Val accuracy: 88.0000%  Loss: 0.149187\n",
      "Epoch: 12  Val accuracy: 88.0000%  Loss: 0.150543\n",
      "Epoch: 13  Val accuracy: 88.0000%  Loss: 0.151457\n",
      "Epoch: 14  Val accuracy: 88.0000%  Loss: 0.151843\n",
      "Epoch: 15  Val accuracy: 88.0000%  Loss: 0.153007\n",
      "Epoch: 16  Val accuracy: 88.0000%  Loss: 0.152910\n",
      "Epoch: 17  Val accuracy: 87.0000%  Loss: 0.154019\n",
      "Epoch: 18  Val accuracy: 87.0000%  Loss: 0.154810\n",
      "Epoch: 19  Val accuracy: 88.0000%  Loss: 0.154820\n",
      "Epoch: 20  Val accuracy: 88.0000%  Loss: 0.155288\n",
      "Epoch: 21  Val accuracy: 88.0000%  Loss: 0.156352\n",
      "Epoch: 22  Val accuracy: 88.0000%  Loss: 0.156052\n",
      "Epoch: 23  Val accuracy: 88.0000%  Loss: 0.156595\n",
      "Epoch: 24  Val accuracy: 88.0000%  Loss: 0.157050\n",
      "Epoch: 25  Val accuracy: 88.0000%  Loss: 0.157328\n",
      "Epoch: 26  Val accuracy: 88.0000%  Loss: 0.157568\n",
      "Epoch: 27  Val accuracy: 88.0000%  Loss: 0.157699\n",
      "Iteration: 10/10 (100.0%)  Loss: 0.00049"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-f264e2077a8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m                     \u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                     feed_dict={X: X_batch.reshape([-1,  sizeB, 1]),\n\u001b[1;32m---> 45\u001b[1;33m                                y: y_batch})\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[0mloss_vals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0macc_vals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 60\n",
    "batch_size =10\n",
    "restore_checkpoint = True\n",
    "\n",
    "n_iterations_per_epoch = x_train.shape[0] // batch_size\n",
    "n_iterations_validation = x_test.shape[0] // batch_size\n",
    "best_loss_val = np.infty\n",
    "checkpoint_path = \"D:/model/\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(1, n_iterations_per_epoch + 1):\n",
    "            X_batch = x_train[(iteration-1)*batch_size: iteration*batch_size]\n",
    "            y_batch = y_train[(iteration-1)*batch_size: iteration*batch_size]\n",
    "            _, loss_train = sess.run(\n",
    "                [training_op, loss],\n",
    "                feed_dict={X: X_batch.reshape([-1, sizeB, 1]),\n",
    "                           y: y_batch,\n",
    "                           mask_with_labels: True})\n",
    "            print(\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\".format(\n",
    "                      iteration, n_iterations_per_epoch,\n",
    "                      iteration * 100 / n_iterations_per_epoch,\n",
    "                      loss_train),\n",
    "                  end=\"\")\n",
    "            if iteration % 10 == 1:\n",
    "                summary_str = merged_summary.eval(feed_dict={X: X_batch.reshape([-1, sizeB, 1]),\n",
    "                                                             y: y_batch})\n",
    "                step = epoch * n_iterations_per_epoch + iteration - 1\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            # 运行训练操作并且评估损失:\n",
    "\n",
    "\n",
    "        # 在每个epoch之后，\n",
    "        # 衡量验证损失和精度：\n",
    "        loss_vals = []\n",
    "        acc_vals = []\n",
    "        for iteration in range(1, n_iterations_validation + 1):\n",
    "            X_batch = x_test[(iteration-1)*batch_size: iteration*batch_size]\n",
    "            y_batch = y_test[(iteration-1)*batch_size: iteration*batch_size]\n",
    "            loss_val, acc_val = sess.run(\n",
    "                    [loss, accuracy],\n",
    "                    feed_dict={X: X_batch.reshape([-1,  sizeB, 1]),\n",
    "                               y: y_batch})\n",
    "            loss_vals.append(loss_val)\n",
    "            acc_vals.append(acc_val)\n",
    "            print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                      iteration, n_iterations_validation,\n",
    "                      iteration * 100 / n_iterations_validation),\n",
    "                  end=\" \" * 10)\n",
    "        loss_val = np.mean(loss_vals)\n",
    "        acc_val = np.mean(acc_vals)\n",
    "        print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}{}\".format(\n",
    "            epoch + 1, acc_val * 100, loss_val,\n",
    "            \" (improved)\" if loss_val < best_loss_val else \"\"))\n",
    "\n",
    "        # 如果有进步就保存模型：\n",
    "        if loss_val < best_loss_val:\n",
    "            save_path = saver.save(sess, checkpoint_path)\n",
    "            best_loss_val = loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
