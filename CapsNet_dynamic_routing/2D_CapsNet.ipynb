{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from confusion_matrix import CM\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from keras import models, optimizers, layers\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding,TimeDistributed,Conv2D,Input, Flatten,Reshape ,MaxPooling2D, Dropout,Activation, LSTM,  Concatenate, Multiply, Lambda\n",
    "from keras.callbacks import ModelCheckpoint,LearningRateScheduler\n",
    "from capsule_layer import CapsuleLayer, Length, Mask, margin_loss, squash\n",
    "\n",
    "import argparse\n",
    "from keras import callbacks\n",
    "from keras import initializers, layers\n",
    "from keras.utils import to_categorical\n",
    "import time\n",
    "\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size2, strides, padding):\n",
    "  \n",
    "    output = layers.Conv2D(filters=dim_capsule*n_channels, kernel_size=kernel_size2, strides=strides, padding=padding,\n",
    "                           name='primarycap_conv1d1')(inputs)\n",
    "    output_BN = layers.BatchNormalization()(output)\n",
    "    output_Act = layers.Activation('relu')(output_BN)\n",
    "    \n",
    "    \n",
    "    #conv2_max = Lambda(lambda x: K.max(x, axis=-1, keepdims=True))(output)\n",
    "    #conv2_mean = Lambda(lambda x: K.mean(x, axis=-1, keepdims=True))(output)\n",
    "    #conv2_concat = layers.Concatenate(axis=-1)([conv2_max, conv2_mean])\n",
    "    \n",
    "    #conv2_sig = layers.Activation('sigmoid')(conv2_max)\n",
    "    \n",
    "    #conv2_fil =layers.Conv1D(filters=1, kernel_size=1,strides=1, padding='same', name='conv1_fil')(conv2_sig)\n",
    "    \n",
    "    #conv2_sig2 = layers.Activation('sigmoid')(conv2_fil)\n",
    "    #mult = output*conv2_sig2\n",
    "    \n",
    "    #conv2_sig2 = layers.Activation('sigmoid')(output)\n",
    "   \n",
    "    #cc = layers.Multiply()([conv2_sig2, conv2_max])\n",
    "    outputs = layers.Reshape(target_shape=[-1, dim_capsule], name='primarycap_reshape')(output_Act)\n",
    "    return layers.Lambda(squash, name='primarycap_squash')(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def capsule(x, y,  ftnums1, ftnums2, ksize1, ksize2, strs, cats_nums, size, dim_caps):\n",
    "    conv1 =Conv2D(filters=ftnums1, \n",
    "                  kernel_size=ksize1,strides=strs, padding='valid', \n",
    "                  activation='relu', name='conv1')(x)\n",
    "    \n",
    "    conv1_BN = layers.BatchNormalization()(conv1)\n",
    "    conv1_Act = layers.Activation('relu')(conv1_BN)\n",
    "\n",
    "    primarycaps = PrimaryCap(conv1_Act, \n",
    "                             dim_capsule=8, n_channels=int(ftnums2/8), \n",
    "                             kernel_size2=ksize2, strides=strs, padding='valid')\n",
    "\n",
    "    digitcaps = CapsuleLayer(num_capsule=cats_nums, dim_capsule=dim_caps, num_routing=3,\n",
    "                                 name='digitcaps')(primarycaps)\n",
    "\n",
    "    out_caps = Length(name='capsnet')(digitcaps)\n",
    "\n",
    "    masked_by_y = Mask()([digitcaps, y])\n",
    "    masked = Mask()(digitcaps)\n",
    "\n",
    "    decoder = models.Sequential(name='decoder')\n",
    "    decoder.add(layers.Dense(512, activation='relu', input_dim=dim_caps*cats_nums))\n",
    "    decoder.add(layers.Dense(1024, activation='relu'))\n",
    "    decoder.add(layers.Dense(size*size, activation='sigmoid'))\n",
    "    decoder.add(layers.Reshape(target_shape=(size, size, 1), name='out_recon'))\n",
    "    \n",
    "    return models, out_caps, decoder(masked_by_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load('/home/yi/forest/hardness/np/pressure_2.npy')\n",
    "finger1 = images[:,:,:24]\n",
    "finger2 = images[:,:,24:48]\n",
    "finger3 = images[:,:,48:]\n",
    "\n",
    "fg1 = finger1[:,:].reshape((780, 72, 24))\n",
    "fg2 = finger2[:,:].reshape((780, 72, 24))\n",
    "fg3 = finger3[:,:].reshape((780, 72, 24))\n",
    "X = np.concatenate((fg1, fg3, fg2), axis=-1)\n",
    "X = np.expand_dims(X, axis=-1)\n",
    "\n",
    "cats_nums = 13\n",
    "y_ohot = np.repeat(np.arange(cats_nums), 60)\n",
    "np.random.seed(42)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y_ohot)))\n",
    "\n",
    "x = X[shuffle_indices]\n",
    "y = y_ohot[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 702 samples, validate on 78 samples\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 6s 9ms/step - loss: 0.4810 - capsnet_loss: 0.4307 - decoder_loss: 0.1283 - capsnet_acc: 0.4473 - val_loss: 0.2584 - val_capsnet_loss: 0.2529 - val_decoder_loss: 0.0140 - val_capsnet_acc: 0.6923\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.1918 - capsnet_loss: 0.1858 - decoder_loss: 0.0152 - capsnet_acc: 0.8575 - val_loss: 0.1279 - val_capsnet_loss: 0.1220 - val_decoder_loss: 0.0150 - val_capsnet_acc: 0.9231\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.0952 - capsnet_loss: 0.0894 - decoder_loss: 0.0148 - capsnet_acc: 0.9601 - val_loss: 0.0734 - val_capsnet_loss: 0.0679 - val_decoder_loss: 0.0139 - val_capsnet_acc: 0.9744\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.0584 - capsnet_loss: 0.0528 - decoder_loss: 0.0144 - capsnet_acc: 0.9886 - val_loss: 0.0605 - val_capsnet_loss: 0.0551 - val_decoder_loss: 0.0139 - val_capsnet_acc: 0.9744\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.0412 - capsnet_loss: 0.0357 - decoder_loss: 0.0141 - capsnet_acc: 0.9915 - val_loss: 0.0574 - val_capsnet_loss: 0.0522 - val_decoder_loss: 0.0133 - val_capsnet_acc: 0.9744\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.0315 - capsnet_loss: 0.0262 - decoder_loss: 0.0135 - capsnet_acc: 0.9957 - val_loss: 0.0432 - val_capsnet_loss: 0.0383 - val_decoder_loss: 0.0126 - val_capsnet_acc: 1.0000\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 5s 8ms/step - loss: 0.0232 - capsnet_loss: 0.0185 - decoder_loss: 0.0122 - capsnet_acc: 0.9972 - val_loss: 0.0344 - val_capsnet_loss: 0.0302 - val_decoder_loss: 0.0107 - val_capsnet_acc: 1.0000\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.0200 - capsnet_loss: 0.0156 - decoder_loss: 0.0112 - capsnet_acc: 0.9986 - val_loss: 0.0339 - val_capsnet_loss: 0.0298 - val_decoder_loss: 0.0105 - val_capsnet_acc: 1.0000\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.0170 - capsnet_loss: 0.0129 - decoder_loss: 0.0105 - capsnet_acc: 1.0000 - val_loss: 0.0371 - val_capsnet_loss: 0.0333 - val_decoder_loss: 0.0096 - val_capsnet_acc: 1.0000\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.0132 - capsnet_loss: 0.0095 - decoder_loss: 0.0094 - capsnet_acc: 1.0000 - val_loss: 0.0284 - val_capsnet_loss: 0.0252 - val_decoder_loss: 0.0084 - val_capsnet_acc: 1.0000\n",
      "78/78 [==============================] - 0s 1ms/step\n",
      "Score for fold 1: capsnet_acc of 1.0; capsnet_acc of 100.0%\n",
      "Train on 702 samples, validate on 78 samples\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 6s 9ms/step - loss: 0.4889 - capsnet_loss: 0.4380 - decoder_loss: 0.1299 - capsnet_acc: 0.4231 - val_loss: 0.2852 - val_capsnet_loss: 0.2788 - val_decoder_loss: 0.0164 - val_capsnet_acc: 0.6923\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.2079 - capsnet_loss: 0.2018 - decoder_loss: 0.0153 - capsnet_acc: 0.8333 - val_loss: 0.1907 - val_capsnet_loss: 0.1838 - val_decoder_loss: 0.0174 - val_capsnet_acc: 0.8205\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.1170 - capsnet_loss: 0.1111 - decoder_loss: 0.0151 - capsnet_acc: 0.9359 - val_loss: 0.1225 - val_capsnet_loss: 0.1158 - val_decoder_loss: 0.0171 - val_capsnet_acc: 0.9103\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.0700 - capsnet_loss: 0.0642 - decoder_loss: 0.0149 - capsnet_acc: 0.9772 - val_loss: 0.0935 - val_capsnet_loss: 0.0869 - val_decoder_loss: 0.0169 - val_capsnet_acc: 0.9487\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.0453 - capsnet_loss: 0.0395 - decoder_loss: 0.0147 - capsnet_acc: 0.9900 - val_loss: 0.0829 - val_capsnet_loss: 0.0763 - val_decoder_loss: 0.0166 - val_capsnet_acc: 0.9615\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.0332 - capsnet_loss: 0.0275 - decoder_loss: 0.0147 - capsnet_acc: 0.9957 - val_loss: 0.0769 - val_capsnet_loss: 0.0704 - val_decoder_loss: 0.0165 - val_capsnet_acc: 0.9487\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.0280 - capsnet_loss: 0.0224 - decoder_loss: 0.0143 - capsnet_acc: 1.0000 - val_loss: 0.0675 - val_capsnet_loss: 0.0612 - val_decoder_loss: 0.0162 - val_capsnet_acc: 0.9615\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.0218 - capsnet_loss: 0.0163 - decoder_loss: 0.0140 - capsnet_acc: 1.0000 - val_loss: 0.0621 - val_capsnet_loss: 0.0560 - val_decoder_loss: 0.0156 - val_capsnet_acc: 0.9744\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.0160 - capsnet_loss: 0.0109 - decoder_loss: 0.0130 - capsnet_acc: 1.0000 - val_loss: 0.0577 - val_capsnet_loss: 0.0526 - val_decoder_loss: 0.0131 - val_capsnet_acc: 0.9615\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.0127 - capsnet_loss: 0.0083 - decoder_loss: 0.0111 - capsnet_acc: 1.0000 - val_loss: 0.0574 - val_capsnet_loss: 0.0527 - val_decoder_loss: 0.0120 - val_capsnet_acc: 0.9615\n",
      "78/78 [==============================] - 0s 1ms/step\n",
      "Score for fold 2: capsnet_acc of 0.9615384630667858; capsnet_acc of 96.15384630667859%\n",
      "Train on 702 samples, validate on 78 samples\n",
      "Epoch 1/10\n",
      "702/702 [==============================] - 6s 9ms/step - loss: 0.4566 - capsnet_loss: 0.4064 - decoder_loss: 0.1279 - capsnet_acc: 0.4473 - val_loss: 0.2685 - val_capsnet_loss: 0.2634 - val_decoder_loss: 0.0128 - val_capsnet_acc: 0.6923\n",
      "Epoch 2/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.1790 - capsnet_loss: 0.1727 - decoder_loss: 0.0159 - capsnet_acc: 0.8618 - val_loss: 0.1473 - val_capsnet_loss: 0.1421 - val_decoder_loss: 0.0134 - val_capsnet_acc: 0.8333\n",
      "Epoch 3/10\n",
      "702/702 [==============================] - 5s 8ms/step - loss: 0.0990 - capsnet_loss: 0.0928 - decoder_loss: 0.0157 - capsnet_acc: 0.9601 - val_loss: 0.1145 - val_capsnet_loss: 0.1094 - val_decoder_loss: 0.0131 - val_capsnet_acc: 0.8974\n",
      "Epoch 4/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.0678 - capsnet_loss: 0.0617 - decoder_loss: 0.0154 - capsnet_acc: 0.9815 - val_loss: 0.0925 - val_capsnet_loss: 0.0874 - val_decoder_loss: 0.0129 - val_capsnet_acc: 0.9615\n",
      "Epoch 5/10\n",
      "702/702 [==============================] - 5s 8ms/step - loss: 0.0429 - capsnet_loss: 0.0369 - decoder_loss: 0.0153 - capsnet_acc: 0.9915 - val_loss: 0.0836 - val_capsnet_loss: 0.0785 - val_decoder_loss: 0.0129 - val_capsnet_acc: 0.9487\n",
      "Epoch 6/10\n",
      "702/702 [==============================] - 5s 8ms/step - loss: 0.0310 - capsnet_loss: 0.0250 - decoder_loss: 0.0152 - capsnet_acc: 0.9972 - val_loss: 0.0689 - val_capsnet_loss: 0.0639 - val_decoder_loss: 0.0127 - val_capsnet_acc: 0.9744\n",
      "Epoch 7/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.0222 - capsnet_loss: 0.0164 - decoder_loss: 0.0149 - capsnet_acc: 0.9986 - val_loss: 0.0623 - val_capsnet_loss: 0.0574 - val_decoder_loss: 0.0127 - val_capsnet_acc: 0.9615\n",
      "Epoch 8/10\n",
      "702/702 [==============================] - 5s 8ms/step - loss: 0.0197 - capsnet_loss: 0.0139 - decoder_loss: 0.0148 - capsnet_acc: 0.9986 - val_loss: 0.0526 - val_capsnet_loss: 0.0477 - val_decoder_loss: 0.0126 - val_capsnet_acc: 0.9615\n",
      "Epoch 9/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.0159 - capsnet_loss: 0.0103 - decoder_loss: 0.0142 - capsnet_acc: 1.0000 - val_loss: 0.0505 - val_capsnet_loss: 0.0461 - val_decoder_loss: 0.0112 - val_capsnet_acc: 0.9744\n",
      "Epoch 10/10\n",
      "702/702 [==============================] - 5s 7ms/step - loss: 0.0128 - capsnet_loss: 0.0079 - decoder_loss: 0.0125 - capsnet_acc: 1.0000 - val_loss: 0.0482 - val_capsnet_loss: 0.0440 - val_decoder_loss: 0.0107 - val_capsnet_acc: 0.9615\n",
      "78/78 [==============================] - 0s 1ms/step\n",
      "Score for fold 3: capsnet_acc of 0.9615384615384616; capsnet_acc of 96.15384615384616%\n",
      "Train on 702 samples, validate on 78 samples\n",
      "Epoch 1/10\n",
      "150/702 [=====>........................] - ETA: 8s - loss: 0.7233 - capsnet_loss: 0.6485 - decoder_loss: 0.1908 - capsnet_acc: 0.1867 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cf090664ff9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     history = Cap.fit([x_train, y_train],[y_train, x_train], batch_size=30, epochs=10,\n\u001b[0;32m---> 33\u001b[0;31m               validation_data=[[x_test, y_test], [y_test, x_test]])\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mtrain_accur_per_fold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"capsnet_acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1646\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2352\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_input = Input(shape=[72, 72, 1])\n",
    "y_input = layers.Input(shape=(cats_nums,))\n",
    "K.set_learning_phase(1)\n",
    "acc_per_fold = []\n",
    "train_accur_per_fold = []\n",
    "test_accur_per_fold = []\n",
    "cm_data_per_fold = []\n",
    "pred_per_fold = []\n",
    "y_test_per_fold = []\n",
    "recon_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "for train, test in kfold.split(X, y):\n",
    "    \n",
    "    y_train = to_categorical(y[train], cats_nums)\n",
    "    y_test = to_categorical(y[test], cats_nums)\n",
    "    x_train = x[train]\n",
    "    x_test = x[test]\n",
    "    models, out_caps, decode_mask = capsule(x_input,y_input, 32, 64, 6, 6,  2, cats_nums, 72, 16)\n",
    "    Cap = models.Model([x_input, y_input], [out_caps, decode_mask])\n",
    "\n",
    "\n",
    "    #lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: 0.001 * (0.99 ** epoch))\n",
    "\n",
    "    #early_stop = callbacks.EarlyStopping(monitor='val_accuracy', mode='max', min_delta=1)\n",
    "    # compile the model\n",
    "    Cap.compile(optimizer=optimizers.Adam(lr=0.001),\n",
    "                  loss=[margin_loss, 'mse'],\n",
    "                  loss_weights=[1., 0.392],\n",
    "                  metrics={'capsnet': 'accuracy'})\n",
    "\n",
    "    history = Cap.fit([x_train, y_train],[y_train, x_train], batch_size=30, epochs=10,\n",
    "              validation_data=[[x_test, y_test], [y_test, x_test]])\n",
    "    \n",
    "    train_accur_per_fold.append(history.history[\"capsnet_acc\"])\n",
    "    test_accur_per_fold.append(history.history[\"val_capsnet_acc\"])\n",
    "   \n",
    "    scores = Cap.evaluate([x_test, y_test], [y_test, x_test], verbose=1)\n",
    "    print(f'Score for fold {fold_no}: {Cap.metrics_names[3]} of {scores[3]}; {Cap.metrics_names[3]} of {scores[3]*100}%')\n",
    "    acc_per_fold.append(scores[3] * 100)\n",
    "\n",
    "    pred = Cap.predict([x_test, y_test])\n",
    "    cm_data = confusion_matrix(y_test.argmax(axis=1), pred[0].argmax(axis=1))\n",
    "    pred_per_fold.append(pred[0])\n",
    "    recon_per_fold.append(pred[1])\n",
    "    y_test_per_fold.append(y[test])\n",
    "    cm_data_per_fold.append(cm_data)\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "train_acc = np.mean(train_accur_per_fold, axis = 0)\n",
    "test_acc = np.mean(test_accur_per_fold, axis = 0)\n",
    "cm_data = np.sum(cm_data_per_fold, axis=0)\n",
    "\n",
    "acc = np.mean(np.array(acc_per_fold))\n",
    "name = \"shape2_\" + \"Cap_exp1\"\n",
    "path = \"/home/yi/forest/Capsule/data/\"\n",
    "np.save(path + 'pred/'+name + '.npy', np.array(pred_per_fold))\n",
    "np.save(path + 'y_test/'+name + '.npy', np.array(y_test_per_fold))\n",
    "np.save(path + 'recon/'+name + '.npy', recon_per_fold)\n",
    "np.save(path + 'cm_data/'+name + '.npy', cm_data)\n",
    "np.save(path + 'final_acc/'+name + '.npy', np.array(acc_per_fold))\n",
    "CM(cm_data, name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
