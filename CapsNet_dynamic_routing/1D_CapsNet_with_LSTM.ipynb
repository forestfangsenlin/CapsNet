{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "\n",
    "from keras import models, optimizers, layers\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding,TimeDistributed,Conv1D,Input, Flatten,Reshape ,MaxPooling2D, Dropout,Activation, LSTM\n",
    "from keras.callbacks import ModelCheckpoint,LearningRateScheduler\n",
    "\n",
    "\n",
    "from keras import callbacks\n",
    "from keras import initializers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import time\n",
    "\n",
    "import glob\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/forest/data/LSTM_capsule/train/\"\n",
    "speechs = os.listdir(base_path )\n",
    "from skimage.transform import resize\n",
    "\n",
    "sizeA = 16000\n",
    "sizeB = 1\n",
    "cat_nums = 10\n",
    "train_image = np.zeros((1, sizeA, sizeB))\n",
    "train_label = [0]\n",
    "for i in range(10):\n",
    "    subfile = os.listdir(base_path + speechs[i] +\"/\")\n",
    "    train_audio_path = base_path + speechs[i] +\"/\"\n",
    "    size = len(subfile)\n",
    "    out_image = np.zeros((size, sizeA, sizeB))\n",
    "    out_label = np.full((size), i)\n",
    "    for index in range(1, len(subfile)):\n",
    "        sample_rate, samples = wavfile.read(str(train_audio_path) + subfile[index])\n",
    "        \n",
    "        \n",
    "        samples = np.float64(samples)\n",
    "    \n",
    "    \n",
    "        log_S = samples/np.sqrt(np.sum(np.square((np.abs(samples))))/len(samples))\n",
    "        where_are_NaNs = np.isnan(log_S)\n",
    "        \n",
    "        log_S[where_are_NaNs] = 0\n",
    "        \n",
    "        log_S = np.pad(log_S, (0, sizeA - len(log_S)), 'constant', constant_values=0)\n",
    "        log_S = log_S.reshape((1, sizeA, sizeB))\n",
    "        out_image[index] = log_S\n",
    "    train_image = np.concatenate((train_image, out_image))\n",
    "    train_label = np.concatenate((train_label, out_label))\n",
    "x_data = train_image[2:]\n",
    "y_data = train_label[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_len = 16000\n",
    "overlap = 2000\n",
    "steps_len = 4000\n",
    "steps = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape (7, 19326, 4000, 1)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(steps):\n",
    "    data.append(x_data[:,(i*overlap):(i*overlap+steps_len)])\n",
    "data = np.asarray(data).astype('float32')\n",
    "\n",
    "print ('data.shape',data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tran = np.transpose(data, (1, 0, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "npad = ((0, 0), (0, 0), (0, 100), (0, 0))\n",
    "data_pad = np.pad(data_tran, pad_width=npad, mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y_data)))\n",
    "split_num = round(len(y_data) * 0.1)\n",
    "\n",
    "x_valid = data_pad[shuffle_indices[: split_num]]\n",
    "y_valid = y_data[shuffle_indices[: split_num]]\n",
    "\n",
    "x_test = data_pad[shuffle_indices[split_num: split_num*2]]\n",
    "y_test = y_data[shuffle_indices[split_num: split_num*2]]\n",
    "\n",
    "x_train = data_pad[shuffle_indices[split_num*2 :]]\n",
    "y_train = y_data[shuffle_indices[split_num*2 :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=[4100, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 =Conv1D(filters=128, kernel_size=101,strides=10, padding='valid', activation='relu', name='conv1')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_batchNorm = layers.BatchNormalization()(conv1)\n",
    "conv1_act = layers.Activation('relu')(conv1_batchNorm)\n",
    "conv1_drop = Dropout(0.5)(conv1_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(vectors, axis=-1):\n",
    "\n",
    "    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
    "    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return scale * vectors\n",
    "\n",
    "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
    "  \n",
    "    output = layers.Conv1D(filters=dim_capsule*n_channels, kernel_size=kernel_size, strides=strides, padding=padding,\n",
    "                           name='primarycap_conv1d')(inputs)\n",
    "    \n",
    "    conv2_batchNorm = layers.BatchNormalization()(output)\n",
    "\n",
    "    outputs = layers.Reshape(target_shape=[-1, dim_capsule], name='primarycap_reshape')(conv2_batchNorm)\n",
    "    return layers.Lambda(squash, name='primarycap_squash')(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "primarycaps = PrimaryCap(conv1_drop, dim_capsule=8, n_channels=16, kernel_size=101, strides=10, padding='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, num_capsule, dim_capsule, num_routing=3,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.num_routing = num_routing\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]\"\n",
    "        self.input_num_capsule = input_shape[1]\n",
    "        self.input_dim_capsule = input_shape[2]\n",
    "\n",
    "        # Transform matrix\n",
    "        self.W = self.add_weight(shape=[self.num_capsule, self.input_num_capsule,\n",
    "                                        self.dim_capsule, self.input_dim_capsule],\n",
    "                                 initializer=self.kernel_initializer,\n",
    "                                 name='W')\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "\n",
    "        inputs_expand = K.expand_dims(inputs, 1)\n",
    "\n",
    "  \n",
    "        inputs_tiled = K.tile(inputs_expand, [1, self.num_capsule, 1, 1])\n",
    "\n",
    "  \n",
    "        inputs_hat = K.map_fn(lambda x: K.batch_dot(x, self.W, [2, 3]), elems=inputs_tiled)\n",
    "\n",
    "\n",
    "        inputs_hat_stopped = K.stop_gradient(inputs_hat)\n",
    "        \n",
    "        b = tf.zeros(shape=[K.shape(inputs_hat)[0], self.num_capsule, self.input_num_capsule])\n",
    "\n",
    "        assert self.num_routing > 0, 'The num_routing should be > 0.'\n",
    "        for i in range(self.num_routing):\n",
    "            c = tf.nn.softmax(b, dim=1)\n",
    "\n",
    "            if i == self.num_routing - 1:\n",
    "   \n",
    "                outputs = squash(K.batch_dot(c, inputs_hat, [2, 2]))  # [None, 10, 16]\n",
    "            else:  \n",
    "                outputs = squash(K.batch_dot(c, inputs_hat_stopped, [2, 2]))\n",
    "\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple([None, self.num_capsule, self.dim_capsule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-9fb066146feb>:42: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "digitcaps = CapsuleLayer(num_capsule=10, dim_capsule=16, num_routing=3,\n",
    "                             name='digitcaps')(primarycaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'digitcaps/mul_2:0' shape=(?, 10, 16) dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digitcaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_caps = Flatten()(digitcaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "capsnet = models.Model(x,  out_caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(TimeDistributed(capsnet,input_shape = (7,4100,1)))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),loss='mse',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y_, n_classes=10):\n",
    "    \n",
    "    y_ = y_.reshape(len(y_))\n",
    "    return np.eye(n_classes)[np.array(y_, dtype=np.int32)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15460, 7, 4100, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv12_batchNorm_act_drop_history = model.fit(x_train, one_hot(y_train),\n",
    "          batch_size =40,\n",
    "          epochs=20, validation_data=(x_test, one_hot(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, one_hot(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
