{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/forest/Matrix-Capsules-EM-Tensorflow/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.layers.python.layers import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5\n",
    "\n",
    "plt.figure(figsize=(n_samples * 2, 3))\n",
    "for index in range(n_samples):\n",
    "    plt.subplot(1, n_samples, index + 1)\n",
    "    sample_image = mnist.train.images[index].reshape(28, 28)\n",
    "    plt.imshow(sample_image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_arch(input, coord_add, is_train: bool, num_classes: int):\n",
    "    batch_size = 50\n",
    "    test1 = []\n",
    "    data_size = int(input.get_shape()[1])\n",
    "    \n",
    "    pose_dim = 9\n",
    "    mat_dim = 9\n",
    "    \n",
    "\n",
    "    tf.logging.info('input shape: {}'.format(input.get_shape()))\n",
    "    \n",
    "    with slim.arg_scope([slim.conv2d], trainable=is_train):\n",
    "        with tf.variable_scope('relu_conv1') as scope:\n",
    "                output = slim.conv2d(input, num_outputs=32, kernel_size=[\n",
    "                                     9, 9], stride=2, padding='VALID', scope=scope, activation_fn=tf.nn.relu)\n",
    "                data_size = int(np.floor((data_size-8)/ 2))\n",
    "                                \n",
    "                assert output.get_shape() == [batch_size, data_size, data_size, 32]\n",
    "                tf.logging.info('conv1 output shape: {}'.format(output.get_shape()))\n",
    "                \n",
    "        \n",
    "        with tf.variable_scope('primary_caps') as scope:\n",
    "\n",
    "                pose = slim.conv2d(output, num_outputs=8 * pose_dim,\n",
    "                                   kernel_size=[4, 4], stride=1, padding='SAME', scope=scope, activation_fn=None)\n",
    "                activation = slim.conv2d(output, num_outputs=8, kernel_size=[\n",
    "                                         2, 2], stride=1, padding='SAME', scope='primary_caps/activation', activation_fn=tf.nn.sigmoid)\n",
    "                pose = tf.reshape(pose, shape=[batch_size, data_size, data_size, 8, pose_dim])\n",
    "                activation = tf.reshape(\n",
    "                    activation, shape=[batch_size, data_size, data_size, 8, 1])\n",
    "                output = tf.concat([pose, activation], axis=4)\n",
    "                output = tf.reshape(output, shape=[batch_size, data_size, data_size, -1])\n",
    "                assert output.get_shape() == [batch_size, data_size, data_size, 8 * (pose_dim+1)]\n",
    "                tf.logging.info('primary capsule output shape: {}'.format(output.get_shape()))\n",
    "                \n",
    "        with tf.variable_scope('conv_caps1') as scope:\n",
    "                \n",
    "            output = kernel_tile(output, 3, 2)\n",
    "            data_size = int(np.floor((data_size - 2) / 2))\n",
    "            output = tf.reshape(output, shape=[batch_size *\n",
    "                                               data_size * data_size, 3 * 3 * 8, (pose_dim+1)])\n",
    "            activation = tf.reshape(output[:, :, pose_dim], shape=[\n",
    "                                    batch_size * data_size * data_size, 3 * 3 * 8, 1])\n",
    "            \n",
    "            with tf.variable_scope('v') as scope:\n",
    "                votes = mat_transform(output[:, :, :pose_dim], mat_dim, tag=True)\n",
    "                tf.logging.info('conv cap 1 votes shape: {}'.format(votes.get_shape()))\n",
    "\n",
    "            with tf.variable_scope('routing') as scope:\n",
    "                miu, activation, _ = em_routing(votes, activation, pose_dim)\n",
    "                tf.logging.info('conv cap 1 miu shape: {}'.format(miu.get_shape()))\n",
    "                tf.logging.info('conv cap 1 activation before reshape: {}'.format(\n",
    "                    activation.get_shape()))\n",
    "\n",
    "            pose = tf.reshape(miu, shape=[batch_size, data_size, data_size, mat_dim, pose_dim])\n",
    "            tf.logging.info('conv cap 1 pose shape: {}'.format(pose.get_shape()))\n",
    "            activation = tf.reshape(\n",
    "                activation, shape=[batch_size, data_size, data_size, mat_dim, 1])\n",
    "            tf.logging.info('conv cap 1 activation after reshape: {}'.format(\n",
    "                activation.get_shape()))\n",
    "            output = tf.reshape(tf.concat([pose, activation], axis=4), [\n",
    "                                batch_size, data_size, data_size, -1])\n",
    "            tf.logging.info('conv cap 1 output shape: {}'.format(output.get_shape()))\n",
    "            \n",
    "        \n",
    "        with tf.variable_scope('conv_caps2') as scope:\n",
    "            output = kernel_tile(output, 3, 1)\n",
    "            data_size = int(np.floor((data_size - 2) / 1))\n",
    "            output = tf.reshape(output, shape=[batch_size *\n",
    "                                               data_size * data_size, 3 * 3 * mat_dim, (pose_dim+1)])\n",
    "            activation = tf.reshape(output[:, :, pose_dim], shape=[\n",
    "                                    batch_size * data_size * data_size, 3 * 3 * mat_dim, 1])\n",
    "\n",
    "            with tf.variable_scope('v') as scope:\n",
    "                votes = mat_transform(output[:, :, :pose_dim], mat_dim)\n",
    "                tf.logging.info('conv cap 2 votes shape: {}'.format(votes.get_shape()))\n",
    "\n",
    "            with tf.variable_scope('routing') as scope:\n",
    "                miu, activation, _ = em_routing(votes, activation, pose_dim)\n",
    "\n",
    "            pose = tf.reshape(miu, shape=[batch_size * data_size * data_size, mat_dim, pose_dim])\n",
    "            tf.logging.info('conv cap 2 pose shape: {}'.format(votes.get_shape()))\n",
    "            activation = tf.reshape(\n",
    "                activation, shape=[batch_size * data_size * data_size, mat_dim, 1])\n",
    "            tf.logging.info('conv cap 2 activation shape: {}'.format(activation.get_shape()))\n",
    "\n",
    "        # It is not clear from the paper that ConvCaps2 is full connected to Class Capsules, or is conv connected with kernel size of 1*1 and a global average pooling.\n",
    "        # From the description in Figure 1 of the paper and the amount of parameters (310k in the paper and 316,853 in fact), I assume a conv cap plus a golbal average pooling is the design.\n",
    "        \n",
    "        with tf.variable_scope('class_caps') as scope:\n",
    "            with tf.variable_scope('v') as scope:\n",
    "                votes = mat_transform(pose, num_classes)\n",
    "\n",
    "                assert votes.get_shape() == [batch_size * data_size *\n",
    "                                             data_size, mat_dim, num_classes, pose_dim]\n",
    "                tf.logging.info('class cap votes original shape: {}'.format(votes.get_shape()))\n",
    "\n",
    "                coord_add = np.reshape(coord_add, newshape=[data_size * data_size, 1, 1, 2])\n",
    "                coord_add = np.tile(coord_add, [batch_size, mat_dim, num_classes, 1])\n",
    "                coord_add_op = tf.constant(coord_add, dtype=tf.float32)\n",
    "\n",
    "                votes = tf.concat([coord_add_op, votes], axis=3)\n",
    "                tf.logging.info('class cap votes coord add shape: {}'.format(votes.get_shape()))\n",
    "                \n",
    "            with tf.variable_scope('routing') as scope:\n",
    "                miu, activation, test2 = em_routing(\n",
    "                    votes, activation, num_classes)\n",
    "                tf.logging.info(\n",
    "                    'class cap activation shape: {}'.format(activation.get_shape()))\n",
    "                tf.summary.histogram(name=\"class_cap_routing_hist\",\n",
    "                                     values=test2)\n",
    "\n",
    "            output = tf.reshape(activation, shape=[\n",
    "                                batch_size, data_size, data_size, num_classes])\n",
    "            \n",
    "        tf.logging.info('output shape: {}'.format(output.get_shape()))\n",
    "            \n",
    "        output = tf.reshape(tf.nn.avg_pool(output, ksize=[1, data_size, data_size, 1], strides=[\n",
    "                            1, 1, 1, 1], padding='VALID'), shape=[batch_size, num_classes])\n",
    "        \n",
    "        tf.logging.info('output shape: {}'.format(output.get_shape()))\n",
    "        \n",
    "        pose = tf.nn.avg_pool(tf.reshape(miu, shape=[batch_size, data_size, data_size, -1]), ksize=[\n",
    "                              1, data_size, data_size, 1], strides=[1, 1, 1, 1], padding='VALID')\n",
    "        \n",
    "        tf.logging.info('pose shape: {}'.format(pose.get_shape()))\n",
    "        \n",
    "        pose_out = tf.reshape(pose, shape=[batch_size, num_classes, (mat_dim+2)])\n",
    "        \n",
    "        tf.logging.info('pose_out shape: {}'.format(pose_out.get_shape()))\n",
    "    return output, pose_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_tile(input, kernel, stride):\n",
    "    # output = tf.extract_image_patches(input, ksizes=[1, kernel, kernel, 1], strides=[1, stride, stride, 1], rates=[1, 1, 1, 1], padding='VALID')\n",
    "\n",
    "    input_shape = input.get_shape()\n",
    "    tile_filter = np.zeros(shape=[kernel, kernel, input_shape[3],\n",
    "                                  kernel * kernel], dtype=np.float32)\n",
    "    for i in range(kernel):\n",
    "        for j in range(kernel):\n",
    "            tile_filter[i, j, :, i * kernel + j] = 1.0\n",
    "\n",
    "    tile_filter_op = tf.constant(tile_filter, dtype=tf.float32)\n",
    "    output = tf.nn.depthwise_conv2d(input, tile_filter_op, strides=[\n",
    "                                    1, stride, stride, 1], padding='VALID')\n",
    "    output_shape = output.get_shape()\n",
    "    output = tf.reshape(output, shape=[int(output_shape[0]), int(\n",
    "        output_shape[1]), int(output_shape[2]), int(input_shape[3]), kernel * kernel])\n",
    "    output = tf.transpose(output, perm=[0, 1, 2, 4, 3])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_transform(input, caps_num_c,  tag=False):\n",
    "    batch_size = int(input.get_shape()[0])\n",
    "    caps_num_i = int(input.get_shape()[1])\n",
    "    output = tf.reshape(input, shape=[batch_size, caps_num_i, 1, 3, 3])#############\n",
    "    # the output of capsule is miu, the mean of a Gaussian, and activation, the sum of probabilities\n",
    "    # it has no relationship with the absolute values of w and votes\n",
    "    # using weights with bigger stddev helps numerical stability\n",
    "    w = slim.variable('w', shape=[1, caps_num_i, caps_num_c, 3, 3], dtype=tf.float32,############\n",
    "                      initializer=tf.truncated_normal_initializer(mean=0.0, stddev=1.0))\n",
    "\n",
    "    w = tf.tile(w, [batch_size, 1, 1, 1, 1])\n",
    "    output = tf.tile(output, [1, 1, caps_num_c, 1, 1])\n",
    "    votes = tf.reshape(tf.matmul(output, w), [batch_size, caps_num_i, caps_num_c, 9])#############最后一维从 改\n",
    "\n",
    "    return votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def em_routing(votes, activation, caps_num_c, tag=False):\n",
    "    iter_routing = 2\n",
    "    epsilon = 1e-9\n",
    "    test = []\n",
    "\n",
    "    batch_size = int(votes.get_shape()[0])\n",
    "    caps_num_i = int(activation.get_shape()[1])\n",
    "    n_channels = int(votes.get_shape()[-1])\n",
    "\n",
    "    sigma_square = []\n",
    "    miu = []\n",
    "    activation_out = []\n",
    "    beta_v = slim.variable('beta_v', shape=[caps_num_c, n_channels], dtype=tf.float32,\n",
    "                           initializer=tf.constant_initializer(0.0))\n",
    "    beta_a = slim.variable('beta_a', shape=[caps_num_c], dtype=tf.float32,\n",
    "                           initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "    # votes_in = tf.stop_gradient(votes, name='stop_gradient_votes')\n",
    "    # activation_in = tf.stop_gradient(activation, name='stop_gradient_activation')\n",
    "    votes_in = votes\n",
    "    activation_in = activation\n",
    "    \n",
    "    for iters in range(iter_routing):\n",
    "        # if iters == cfg.iter_routing-1:\n",
    "\n",
    "        # e-step\n",
    "        if iters == 0:\n",
    "            r = tf.constant(np.ones([batch_size, caps_num_i, caps_num_c], dtype=np.float32) / caps_num_c)\n",
    "        else:\n",
    "            # Contributor: Yunzhi Shi\n",
    "            # log and exp here provide higher numerical stability especially for bigger number of iterations\n",
    "            log_p_c_h = -tf.log(tf.sqrt(sigma_square)) - \\\n",
    "                        (tf.square(votes_in - miu) / (2 * sigma_square))\n",
    "            log_p_c_h = log_p_c_h - \\\n",
    "                        (tf.reduce_max(log_p_c_h, axis=[2, 3], keep_dims=True) - tf.log(10.0))\n",
    "            p_c = tf.exp(tf.reduce_sum(log_p_c_h, axis=3))\n",
    "\n",
    "            ap = p_c * tf.reshape(activation_out, shape=[batch_size, 1, caps_num_c])\n",
    "\n",
    "            # ap = tf.reshape(activation_out, shape=[batch_size, 1, caps_num_c])\n",
    "\n",
    "            r = ap / (tf.reduce_sum(ap, axis=2, keep_dims=True) + epsilon)\n",
    "\n",
    "        # m-step\n",
    "        r = r * activation_in\n",
    "        r = r / (tf.reduce_sum(r, axis=2, keep_dims=True)+epsilon)\n",
    "\n",
    "        r_sum = tf.reduce_sum(r, axis=1, keep_dims=True)\n",
    "        r1 = tf.reshape(r / (r_sum + epsilon),\n",
    "                        shape=[batch_size, caps_num_i, caps_num_c, 1])\n",
    "\n",
    "        miu = tf.reduce_sum(votes_in * r1, axis=1, keep_dims=True)\n",
    "        sigma_square = tf.reduce_sum(tf.square(votes_in - miu) * r1,\n",
    "                                     axis=1, keep_dims=True) + epsilon\n",
    "        \n",
    "        if iters == iter_routing-1:\n",
    "            r_sum = tf.reshape(r_sum, [batch_size, caps_num_c, 1])\n",
    "            cost_h = (beta_v + tf.log(tf.sqrt(tf.reshape(sigma_square,\n",
    "                                                         shape=[batch_size, caps_num_c, n_channels])))) * r_sum\n",
    "\n",
    "            activation_out = tf.nn.softmax(0.01 * (beta_a - tf.reduce_sum(cost_h, axis=2)))\n",
    "        else:\n",
    "            activation_out = tf.nn.softmax(r_sum)\n",
    "        # if iters <= cfg.iter_routing-1:\n",
    "        #     activation_out = tf.stop_gradient(activation_out, name='stop_gradient_activation')\n",
    "\n",
    "    return miu, activation_out, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coord_add(dataset_name: str):\n",
    "    import numpy as np\n",
    "    # TODO: get coord add for cifar10/100 datasets (32x32x3)\n",
    "    options = {'mnist': ([[[8., 8.], [12., 8.]],\n",
    "                          [[8., 12.], [12., 12.]]], 28.),\n",
    "               'smallNORB': ([[[8., 8.], [12., 8.], [16., 8.], [24., 8.]],\n",
    "                              [[8., 12.], [12., 12.], [16., 12.], [24., 12.]],\n",
    "                              [[8., 16.], [12., 16.], [16., 16.], [24., 16.]],\n",
    "                              [[8., 24.], [12., 24.], [16., 24.], [24., 24.]]], 32.)\n",
    "               }\n",
    "    coord_add, scale = options[dataset_name]\n",
    "\n",
    "    coord_add = np.array(coord_add, dtype=np.float32) / scale\n",
    "\n",
    "    return coord_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_add = get_coord_add('mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(shape=[50, 28, 28, 1], dtype=tf.float32, name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, pose_out = build_arch(X, coord_add, is_train=True, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spread_loss(output, pose_out, x, y, m):\n",
    "    \n",
    "    batch_size = 50\n",
    "\n",
    "    num_class = int(output.get_shape()[-1])\n",
    "    data_size = int(x.get_shape()[1])\n",
    "\n",
    "    y = tf.one_hot(y, num_class, dtype=tf.float32)\n",
    "\n",
    "    # spread loss\n",
    "    output1 = tf.reshape(output, shape=[batch_size, 1, num_class])\n",
    "    y = tf.expand_dims(y, axis=2)\n",
    "    at = tf.matmul(output1, y)\n",
    "    \"\"\"Paper eq(5).\"\"\"\n",
    "    mb = at - output1\n",
    "    loss = tf.matmul(tf.square(tf.maximum(0., m - mb)), 1. - y)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "\n",
    "    pose_out = tf.reshape(tf.multiply(pose_out, y), shape=[batch_size, -1])\n",
    "    tf.logging.info(\"decoder input value dimension:{}\".format(pose_out.get_shape()))\n",
    "    \n",
    "    with tf.variable_scope('decoder'):\n",
    "        pose_out = slim.fully_connected(pose_out, 512, trainable=True, weights_regularizer=tf.contrib.layers.l2_regularizer(5e-04))\n",
    "        pose_out = slim.fully_connected(pose_out, 1024, trainable=True, weights_regularizer=tf.contrib.layers.l2_regularizer(5e-04))\n",
    "        pose_out = slim.fully_connected(pose_out, data_size * data_size,\n",
    "                                        trainable=True, activation_fn=tf.sigmoid, weights_regularizer=tf.contrib.layers.l2_regularizer(5e-04))\n",
    "\n",
    "        x = tf.reshape(x, shape=[batch_size, -1])\n",
    "        reconstruction_loss = tf.reduce_mean(tf.square(pose_out - x))\n",
    "\n",
    "    if False:\n",
    "        # regularization loss\n",
    "        regularization = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "        # loss+0.0005*reconstruction_loss+regularization#\n",
    "        loss_all = tf.add_n([loss] + [0.0005 * data_size* data_size * reconstruction_loss] + regularization)\n",
    "    else:\n",
    "        loss_all = tf.add_n([loss] + [0.0005 * data_size* data_size * reconstruction_loss])\n",
    "\n",
    "    return loss_all, loss, reconstruction_loss, pose_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(logits, labels):\n",
    "    batch_size = 50\n",
    "    logits_idx = tf.to_int32(tf.argmax(logits, axis=1))\n",
    "    logits_idx = tf.reshape(logits_idx, shape=(batch_size,))\n",
    "    correct_preds = tf.equal(tf.to_int32(labels), logits_idx)\n",
    "    accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32)) / batch_size\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_op = tf.placeholder(dtype=tf.float32, shape=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(shape=[None], dtype=tf.int32, name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, spread_loss, mse, _ = spread_loss(\n",
    "                    output, pose_out, X, y, m_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = test_accuracy(output, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.group(\n",
    "                   tf.global_variables_initializer(),\n",
    "                   tf.local_variables_initializer ()\n",
    "          )\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "batch_size = 50\n",
    "       \n",
    "restore_checkpoint = True\n",
    "\n",
    "n_iterations_per_epoch = mnist.train.num_examples // batch_size\n",
    "n_iterations_validation = mnist.validation.num_examples // batch_size\n",
    "best_loss_val = np.infty\n",
    "checkpoint_path = \"./my_capsule_network4\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    \n",
    "    loss1_vals = []\n",
    "    m_vals = np.zeros((1))\n",
    "    loss1_vals = np.zeros((1, 50, 10))\n",
    "    \n",
    "    m_min = 0.2\n",
    "    m_max = 0.9\n",
    "    m = m_max\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        for iteration in range(1, n_iterations_per_epoch + 1):\n",
    "            try:\n",
    "                X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "                _, loss_train= sess.run(\n",
    "                    [training_op, loss],\n",
    "                    feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                               y: y_batch,\n",
    "                               m_op: m})\n",
    "                print(\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}  m : {:.5f}\".format(\n",
    "                          iteration, n_iterations_per_epoch,\n",
    "                          iteration * 100 / n_iterations_per_epoch,\n",
    "                          loss_train,  m),\n",
    "                      end=\"\")\n",
    "            # 运行训练操作并且评估损失:\n",
    "            except KeyboardInterrupt:\n",
    "                sess.close()\n",
    "                sys.exit()\n",
    "            except tf.errors.InvalidArgumentError:\n",
    "                logger.warning('%d iteration contains NaN gradients. Discard.' % step)\n",
    "                continue\n",
    "\n",
    "            \n",
    "        loss_vals = []\n",
    "        acc_vals = []\n",
    "        \n",
    "        \n",
    "        for iteration in range(1, n_iterations_validation + 1):\n",
    "            X_batch, y_batch = mnist.validation.next_batch(batch_size)\n",
    "            loss_val, acc_val = sess.run(\n",
    "                    [loss, accuracy],\n",
    "                    feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                               y: y_batch,\n",
    "                               m_op: m})\n",
    "            loss_vals.append(loss_val)\n",
    "            acc_vals.append(acc_val)\n",
    "            print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                      iteration, n_iterations_validation,\n",
    "                      iteration * 100 / n_iterations_validation),\n",
    "                  end=\" \" * 10)\n",
    "            \n",
    "\n",
    "        loss_val = np.mean(loss_vals)\n",
    "        acc_val = np.mean(acc_vals)\n",
    "        print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.5f}{}\".format(\n",
    "            epoch + 1, acc_val * 100, loss_val,\n",
    "            \" (improved)\" if loss_val < best_loss_val else \"\"))\n",
    "        \n",
    "            \n",
    "\n",
    "        # And save the model if it improved:\n",
    "        if loss_val < best_loss_val:\n",
    "            save_path = saver.save(sess, checkpoint_path)\n",
    "            best_loss_val = loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
